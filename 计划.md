
#第一章：Python /R 基础
教学目标
复习 Python 基础语法
对比 Python 学习 R 的简易语法
学会撰写 Python 风格代码
掌握 Python 内置数据结构
难点
如何利用 Python 类当中的内置函数提升代码撰写的效率
如何熟练操作 Python 常见的数据结构
如何利用装饰器修改函数的表现
详细内
 Python/R 开发环境的搭建
Jupyter Notebook 使用基本指南、快捷键和魔法函数
PyCharm IDE 的使用指南和常用功能
 Python 面向过程和面对象的基本概念回顾
深入了解 Python 的对象：使用 Python  Object 的内置函数实现优雅有效的编程
 Python 常见数据结构（list、set、dict、namedtuple 等）的操作
 Python 函数式编程基础及应用：lambda 函数的编写、如何通过装饰器优雅地修改函数的行为
R 的简单介绍：环境搭建、控制循环、调用函数

#第二章：Python 性能调优指南

教学目标
掌握 Python 瓶颈的识别方法
掌握 Cython 的基本语法
掌握 Python 的多进程编程
难点
如何使用 Profiler 有效地识别 Python 代码中的瓶颈
如何根据代码瓶颈进行调优
如何通过 Cython 提升 Python 代码的速度
如何处理多进程当中的共享数据

详细内容
代码性能优化的基本过程和方法论
如何定位 Python 代码中的瓶颈：使用 Profiler 对函数和行进行 Profile，使用 VTune 的基本方法
Cython 基本语法：如何定义 Cython 函数及类、Cython 对象和 Python 对象的联系、区别和交互，如何实现 Python 和 C++ 交互
Cython Module 的编译、编译选项及注意事项
提升 Cython 性能的方法：如何测量 Cython 函数的效率、如何对 numpy 数组进行调整以提升运行速度、如何使用 OpenMP
基于 Ray 的多进程编程：Ray 的基本语法、如何共享数据并避免 Race condition

#第三章：Python/R 中的数据操作及可视化
教学目标
掌握 Python 中的矩阵运算
通过 Python 实现数据的处理
通过 R 的 dplyr 实现方便的数据探查
实现数据的可视化
难点
高维矩阵运算中的 Broadcast 和 Einsum
数据分析中的 GROUP BY 和 JOIN 操作
TensorBoard 的可视化使用操作
详细内容
numpy 基础操作及使用技巧：常见的 numpy 函数、基本的矩阵 index 操作、矩阵/向量之间的运算操作、Broadcast 机制、Einsum 的使用和理解
Pandas 基础操作及使用技巧：数据的读取和存储、如何进行复杂的数据筛选、Pandas 当中的 Map 和 Reduce 操作、Pandas 的 GROUP BY 操作、多数据框的 CONCAT 和 JOIN
R 的 DataFrame 及操作（类比 Pandas）
dplyr 的使用：如何使用简洁的语句对数据进行探索
Matplotlib 常见的绘图操作：直方图、散点图、箱型图等
TensorBoard 的基础操作

#第四章：机器学习基本概念
教学目标
掌握机器学习建模及评估的基本概念
掌握基于损失函数和极大似然函数的估计
掌握简单的矩阵求导
难点
基于损失函数的极大似然函数
极大似然函数的推导
矩阵求导的推导
详细内容
机器学习基本概念：随机性的定义、来源及其对模型拟合的影响、评估模型的方法、模型的可识别性问题、多重共线性的检验
机器学习建模流程：传统建模方法和预测性建模方法的区别、单模型和模型平均建模方法、模型参数调整、衍生变量构建及模型平均方法之间的协同
常见的基于损失函数的模型及推导：回归问题和分类问题中常见的损失函数
极大似然估计方法：极大似然估计的数学定义，常见分布（均匀分布、正态分布、二项分布、泊松分布等）的数学形式，常见分布的几大似然估计推导
EM 算法推导
张量求导复习：如何对非标准矩阵形式进行简单求导，手撸 CNN 和 RNN 的求导

#第五章：手撸机器学习算法
教学目标
实现简单模型的参数估计过程
掌握从数学公式到算法实现的基本方法
学会 Debug 自己实现的算法
学会对自己实现的算法进行调优
难点
如何检验自己实现的机器学习算法的正确性
如何 Debug 自己实现的算法
如何对自己实现的算法进行性能调优
详细内容
推导逻辑回归和 Tobit 模型的极大似然函数
scipy.optimize 模块的使用
实现逻辑回归和 Tobit 模型的极大似然估计、如何对估计做收敛诊断、如何加速算法的收敛速度、算法性能瓶颈调研及优化
Proximal Method 及 L1 正则化、Proximal Method 的原理、Proximal Method 的 Python 实现、L1 正则化的原理及效果、L1 正则化的逻辑回归实现

#第六章：经典机器学习算法及调优
教学目标
掌握经典机器学习算法的数学原理
理解经典机器学习算法的优势和劣势
掌握经典机器学习算法的调参经验
难点
理解经典机器学习算法的适用性
根据模型评估结果选择合适的参数
详细内容
模型评估的注意事项
经典机器学习算法（线性回、逻辑回归、支持向量机、最近邻方法）的原理及适用性
基于树的方法（决策树、随机森林、XgBoost、LightGBM、CatBoost）的原理及适用性
常用的统计学模型原理：GLM、GAM、贝叶斯方法和结构方程模型及 R 实现
经典机器学习算法和基于树的方法的重要参数讲解
经典机器学习方法的 Python 实现：sklearn/cuml 使用讲解、XgBoost、LightGBM 和 CatBoost 使用讲解


#第七章：模型集成方法
教学目标
掌握模型集成的思想
掌握常见的 Stacking 技巧
掌握如何将 Metadata Features 引入到 Stacking 当中
难点
根据数据特征选择合适的模型集成方法
如何引入合适的 Metadata Features
详细内容
常见的模型平均方法：算术平均、几何平均和 Rank Average，如何选择合适的子模型
Stacking 及 Blending 的通用方法：Stacking 和 Blending 的原理、如何对 Stacking 和 Blending 结果做检验、Stacking 和 Blending 的实现
降维方法：常见降维方法（PCA 和 tSNE）的数学形式及优缺点、基于 sklearn/cuml 的降维方法实现
Metadata Features 在模型集成中的应用：如何通过原始预测生成 Metadata Features、如何通过降维和 KNN 引入 Metadata Features


#第八章：特征工程方法论

教学目标
掌握基于业务理解的衍生变量构建方法
掌握常见的衍生变量构建方法
掌握如何根据探索性分析和 Bad case 分析
掌握如何有效地测试衍生变量构建的效果
难点
如何根据业务理解构建有创造性的衍生变量
常见的衍生变量构建方法的选择
如何有效地进行探索性分析和 Bad case 分析
详细内容
衍生变量构建的方法论：如何有效地构建衍生变量并验证衍生变量的效果
如何根据业务说明从多角度创造性地构建衍生变量
常用的衍生变量构建方法：连续变量和离散变量的常用 Encoding 原理及其适用性、常用 Encoder 的实现、缺失值填充方法、常用变量选择方法（基于统计指标、基于解释变量相关性、基于 Permutation loss 、基于模型、基于 SHAP 值等）的原理和实现
如何通过常见的探索性分析方法及 Bad case 分析方法构造衍生变量

#第九章：深度学习基础及常见网络

教学目标
掌握深度学习的基础概念
掌握常见的网络设计模式
难点
常见的网络设计模式的应用
不同的 Embedding 设计方法
Attention 机制的灵活应用

详细内容
深度学习的基本概念：神经网络的数学形式、后向传递、神经网络的经典优化算法、神经网络优化过程的注意事项
神经网络构成的基本要素：全连接层、激活函数、Normalization 和 Dropout
常见的神经网络设计模式：Embedding、Attention、Memory、Residual/Dense Connection 等结构的数学形式及适用性
经典神经网络：MLP、CNN、RNN 常见结构的数学形式及使用范畴
Transformer：Transformer 结构的数学形式、Embedding 和 Transformer 在表征学习当中的应用、Transformer 的结构改进方式
推荐系统经典模型介绍：Neural FM 系列模型的数学形式及其适用性

#第十章：PyTorch 基础

教学目标
掌握 PyTorch 的基本语法
通过 PyTorch 实现经典的深度学习网络架构
难点
训练/评估框架的撰写
Embedding 及 Attention 的实现
详细内容
PyTorch 的 Tensor 操作
PyTorch 的数据读取操作：如何构建 Dataset 和 Dataloader
PyTorch 的训练/评估框架撰写：常见的训练评估流程、如何实现多 GPU、分布式训练、低精度训练及实现、模型状态的保存及 Finetune
RNN 实现：手撸 LSTM，Tree-LSTMs 及其 Attention 变种
Embedding 实现：实现 Entity Embedding、在 Entity Embedding 中引入 Vicinity INFO、Skip-Gram 模型的实现
Transformer 的实现：实现经典的 Transformer 架构及其变种
xDeepFM 的实现：如何通过神经网络处理高维稀疏数据

#第十一章：深度学习模型调优

教学目标 
理解深度学习训练的基本过程与调参方法论
掌握预训练模型的方法
掌握提升模型准确度的其他方法
难点
根据模型训练情况选择合适的技巧
根据模型训练情况更改模型的结构
详细内容
常见优化器的数学形式及实现：SGD、Momentum 的引入、Adagrad、RMSProp、Adam、AdamW、RADAM 及 Lookahead 的数学形式、重要参数及实现的注意事项
Babysit 炼丹过程：初始化的方法、学习率和 Batch size 的调整、Gradient Clipping
表格化数据的预训练方法：Auto Encoder 的数学原理及实现、Transformer 的预训练方法探索
如何提高模型的鲁棒性：Adversarial Training 的基本思想、FGSM 方法的数学原理及实现、其他 Adversarial Training 方法
如何通过引进多个损失函数加速训练收敛
Semi-Supervised Learning 的原理及实现

#第十二章：AutoML 初探
教学目标：
理解常见的 AutoML 框架和问题
理解自动构建变量的方法
理解遗传算法和增强学习的基本概念以及如何进行结合
理解 TabNet 以及如何通过 Gumbel trick 进行可微分的网络搜索
难点：
RL 的数学形式、不同算法及调优注意事项
Gumbel-Softmax trick 及其应用
详细内容：
AutoML 的基本问题：超参数寻找、自动变量构造、网络搜索
RL 基本概念：Q-learning 和 Policy Gradient 的基本推导和实现、Gym 的搭建和调试、PPO 算法
Gumbel trick：如何将离散问题转换为可微问题
TabNet：如何构建可解释的深度学习模型
基于 Gumbel trick 的 Differentiable Architecture Search

#第十三章：JAX 简介（选修）
教学目标：
介绍 JAX 框架
通过 JAX 框架实现网络训练和部署的加速
难点：
理解 JAX 函数式撰写方法
详细内容：
通过 JAX 快速构建网络
通过 JAX 的 JIT 功能实现计算的加速
使用 TF Dataloader 实现简单的神经网络计算

#第十四章：TensorRT 简介（选修）
教学目标：
介绍 TensorRT 的使用方式和基本模式
介绍如何构建 TensorRT 自定义的操作算子
难点
如何构建自定义的 Cuda Kernel
如何有效地优化 GPU 的使用

详细内容：
TensorRT 基本构造、环境搭建以及基本工作流程
GPU 基本硬件构造特性及相应优化空间
基本 CUDA Kernel 的写作
CUDA Reduce Kernel 的写作
如何将 PyTorch 的模型导入 TensorRT
TensorRT 的常见设置
如何构建用户自定义的操作算子